{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX-gWsRYFzLy"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "###    Họ và tên: Hồ Công Lượng\n",
        "###    MSSV: 19120572\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ue25ga8GXR7"
      },
      "source": [
        "# 1. Cài đặt môi trường"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IgMSAz23oliE"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q segmentation-models\n",
        "!pip install -q tensorflow==2.1\n",
        "!pip install -q keras==2.3.1\n",
        "!pip install -q tensorflow-estimator==2.1.\n",
        "## Imports libs\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhIaEcQANrlY",
        "outputId": "d1a1919b-4eee-4ec2-b610-9289923a99a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf8AdFkNGbeh"
      },
      "source": [
        "# 2. Tải dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ggsi1VW7ZeNY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WyuzZhuGaA_R",
        "outputId": "ba9ca8f3-675d-4d6b-c021-547e53ff9d29"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c0d25b33-6a9f-4ed5-909e-604fc748b341\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0d25b33-6a9f-4ed5-909e-604fc748b341')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0d25b33-6a9f-4ed5-909e-604fc748b341 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0d25b33-6a9f-4ed5-909e-604fc748b341');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/CNN_LSTM/IMDB Dataset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrJoiuctGh-m"
      },
      "source": [
        "# 3. Xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8SMEcAnqr_5i"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "exclude = string.punctuation\n",
        "def remove_html_tags(text):\n",
        "    re_html = re.compile('<.*?>')\n",
        "    return re_html.sub(r'', text)\n",
        "\n",
        "def remove_punc(text):\n",
        "    return text.translate(str.maketrans('', '', exclude))\n",
        "\n",
        "df['review'] = df['review'].apply(remove_html_tags)\n",
        "df['review'] = df['review'].apply(remove_punc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fFYXQ7XUeL7b"
      },
      "outputs": [],
      "source": [
        "# Tách 2 tập positive và negative riêng biệt\n",
        "df_pos = np.array(df[df['sentiment'] == 'positive'].reset_index()['review'])\n",
        "df_neg = np.array(df[df['sentiment'] == 'negative'].reset_index()['review'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "88cXvrbY8dVY"
      },
      "outputs": [],
      "source": [
        "word2id = {}\n",
        "id2word ={}\n",
        "index = 1\n",
        "# Word embedding\n",
        "def word_embedding(reviews):\n",
        "  global word2id\n",
        "  global id2word\n",
        "  global index\n",
        "  temp = []\n",
        "  for rev in reviews:\n",
        "    rev = rev.replace('\\n', \"\")\n",
        "    ids = np.array([], dtype='int32')\n",
        "    for word in rev.split(' '):\n",
        "      word = word.lower()\n",
        "      if word in word2id:\n",
        "        ids = np.append(ids, word2id[word])\n",
        "      else:\n",
        "        if word != '':\n",
        "          word2id[word] = index\n",
        "          id2word[index] = word\n",
        "          ids = np.append(ids, index)\n",
        "          index = index + 1\n",
        "    if len(ids) > 0:\n",
        "      temp.append(ids)\n",
        "\n",
        "  return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z6-nvQDocJ6x"
      },
      "outputs": [],
      "source": [
        "positive = word_embedding(df_pos)\n",
        "negative = word_embedding(df_neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww_EnI-MGnom"
      },
      "source": [
        "# 4. Tạo nhãn và chia data thành các tập train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sanl02Zejfw",
        "outputId": "b68773d8-265e-4425-c567-6d6036b9fbe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42000,) (42000, 2)\n",
            "(4000,) (4000, 2)\n",
            "(4000,) (4000, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ],
      "source": [
        "y_pos = []\n",
        "for i in positive:\n",
        "  y_pos.append([1,0])\n",
        "y_pos = np.array(y_pos)\n",
        "\n",
        "y_neg = []\n",
        "for i in negative:\n",
        "  y_neg.append([0, 1])\n",
        "y_neg = np.array(y_neg)\n",
        "\n",
        "# Lấy 21000 samples cho tập train, 2000 samples cho tập test và 2000 samples cho tập validate4\n",
        "# Train\n",
        "pos_train = positive[0:21000]\n",
        "neg_train = negative[0:21000]\n",
        "y_pos_train = y_pos[0:21000]\n",
        "y_neg_train = y_neg[0:21000]\n",
        "\n",
        "# Test\n",
        "pos_test = positive[21000:23000]\n",
        "neg_test = negative[21000:23000]\n",
        "y_pos_test = y_pos[21000:23000]\n",
        "y_neg_test = y_neg[21000:23000]\n",
        "\n",
        "# Validate\n",
        "pos_val = positive[23000:25000]\n",
        "neg_val = negative[23000:25000]\n",
        "y_pos_val = y_pos[23000:25000]\n",
        "y_neg_val = y_neg[23000:25000]\n",
        "\n",
        "X_train = np.concatenate([pos_train, neg_train])\n",
        "y_train = np.concatenate([y_pos_train, y_neg_train])\n",
        "\n",
        "X_val = np.concatenate([pos_val, neg_val])\n",
        "y_val = np.concatenate([y_pos_val, y_neg_val])\n",
        "\n",
        "X_test = np.concatenate([pos_test, neg_test])\n",
        "y_test = np.concatenate([y_pos_test, y_neg_test])\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "print(X_val.shape, y_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XzPHNTEG0eq"
      },
      "source": [
        "# 5. Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djlohj9UZa4s",
        "outputId": "40e57eaa-1336-45a3-ff51-1d9949a3efdb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Convolution1D, LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.preprocessing import sequence as sq\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda,concatenate,Input,TimeDistributed,Flatten\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import keras.backend.tensorflow_backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOxQzLymm5X5",
        "outputId": "8ab5c741-d56c-45e6-e5ea-775d7b3a4ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42000 train sequences\n",
            "4000 test sequences\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=150, kernel_size=2, strides=1, padding=\"valid\")`\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=150, kernel_size=2, strides=1, padding=\"valid\")`\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=150, kernel_size=3, strides=1, padding=\"valid\")`\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(activation=\"relu\", filters=150, kernel_size=3, strides=1, padding=\"valid\")`\n"
          ]
        }
      ],
      "source": [
        "# set parameters:\n",
        "max_features = len(word2id) + 1\n",
        "maxlen = 400\n",
        "embedding_dims = 200\n",
        "nb_filter = 150\n",
        "hidden_dims = 100\n",
        "\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')\n",
        "\n",
        "X_train = sq.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sq.pad_sequences(X_test, maxlen=maxlen)\n",
        "X_val = sq.pad_sequences(X_val, maxlen=maxlen)\n",
        "\n",
        "# Build model\n",
        "model = Sequential()\n",
        "\n",
        "input_layer = Input(shape=(maxlen,),dtype='int32', name='main_input')\n",
        "emb_layer = Embedding(max_features,\n",
        "                      embedding_dims,\n",
        "                      input_length=maxlen\n",
        "                      )(input_layer)\n",
        "def max_1d(X):\n",
        "    return K.max(X, axis=1)\n",
        "\n",
        "# 2 filter có filter_length=2\n",
        "con2_1_layer = Convolution1D(nb_filter=nb_filter,\n",
        "                    filter_length=2,\n",
        "                    border_mode='valid',\n",
        "                    activation='relu',\n",
        "                    subsample_length=1)(emb_layer)\n",
        "\n",
        "pool_con2_1_layer = Lambda(max_1d, output_shape=(nb_filter,))(con2_1_layer)\n",
        "\n",
        "con2_2_layer = Convolution1D(nb_filter=nb_filter,\n",
        "                    filter_length=2,\n",
        "                    border_mode='valid',\n",
        "                    activation='relu',\n",
        "                    subsample_length=1)(emb_layer)\n",
        "\n",
        "pool_con2_2_layer = Lambda(max_1d, output_shape=(nb_filter,))(con2_2_layer)\n",
        "\n",
        "# 2 filter có filter_length=3\n",
        "con3_1_layer = Convolution1D(nb_filter=nb_filter,\n",
        "                    filter_length=3,\n",
        "                    border_mode='valid',\n",
        "                    activation='relu',\n",
        "                    subsample_length=1)(emb_layer)\n",
        "\n",
        "pool_con3_1_layer = Lambda(max_1d, output_shape=(nb_filter,))(con3_1_layer)\n",
        "\n",
        "con3_2_layer = Convolution1D(nb_filter=nb_filter,\n",
        "                    filter_length=3,\n",
        "                    border_mode='valid',\n",
        "                    activation='relu',\n",
        "                    subsample_length=1)(emb_layer)\n",
        "\n",
        "pool_con3_2_layer = Lambda(max_1d, output_shape=(nb_filter,))(con3_2_layer)\n",
        "\n",
        "# Concatenate into CNN features\n",
        "cnn_layer = concatenate([pool_con2_1_layer, pool_con2_2_layer, pool_con3_1_layer, pool_con3_2_layer])\n",
        "\n",
        "#LSTM\n",
        "x = Embedding(max_features, embedding_dims, input_length=maxlen)(input_layer)\n",
        "lstm_layer = LSTM(128)(x)\n",
        "\n",
        "# Concatenate CNN layer and LSTM layer\n",
        "cnn_lstm_layer = concatenate([lstm_layer, cnn_layer])\n",
        "\n",
        "dense_layer = Dense(hidden_dims*2, activation='sigmoid')(cnn_lstm_layer)\n",
        "output_layer= Dropout(0.2)(dense_layer)\n",
        "output_layer = Dense(2, trainable=True,activation='softmax')(output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydDmpgAUZOnx",
        "outputId": "6c889982-4a0c-45bd-92ff-055497d51ae9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 4000 samples\n",
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 1119s 27ms/step - loss: 0.5787 - accuracy: 0.6760 - val_loss: 0.3451 - val_accuracy: 0.8558\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 1110s 26ms/step - loss: 0.2572 - accuracy: 0.8980 - val_loss: 0.2647 - val_accuracy: 0.8865\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 1115s 27ms/step - loss: 0.1626 - accuracy: 0.9413 - val_loss: 0.2645 - val_accuracy: 0.8955\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 1131s 27ms/step - loss: 0.1069 - accuracy: 0.9653 - val_loss: 0.3037 - val_accuracy: 0.8953\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 1127s 27ms/step - loss: 0.0698 - accuracy: 0.9797 - val_loss: 0.3855 - val_accuracy: 0.8850\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fa5da8daad0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train model \n",
        "batch_size = 1024\n",
        "nb_epoch = 5\n",
        "\n",
        "model = Sequential()\n",
        "model = Model(input=[input_layer], output=[output_layer])\n",
        "adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=1e-06)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"adamax\",\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/CNN_LSTM/weights.hdf5',\n",
        "                              monitor='val_acc', verbose=0, save_weights_only=True,\n",
        "                              mode='max')\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          nb_epoch=nb_epoch,\n",
        "          callbacks=[checkpoint],\n",
        "          validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Pp4PoF9GUbY6"
      },
      "outputs": [],
      "source": [
        "# Save checkpoint \n",
        "model.save_weights(\"/content/drive/MyDrive/CNN_LSTM/weights.hdf5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRqnmn7RG9Xh"
      },
      "source": [
        "# 6. Đánh giá model trên tập test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxOiKeOsnqVj",
        "outputId": "1cd9b527-33a7-4038-a2a0-1345248f00ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000/4000 [==============================] - 27s 7ms/step\n",
            "acc =  0.8872500061988831\n"
          ]
        }
      ],
      "source": [
        "new_model = Model(input=[input_layer], output=[output_layer])\n",
        "\n",
        "new_model.load_weights('/content/drive/MyDrive/CNN_LSTM/weights.hdf5')\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=\"adamax\",\n",
        "              metrics=['accuracy'])\n",
        "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "\n",
        "print('acc = ', acc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "2f155fbeb9494e5ce992090b8427abe3542dae7719d8ea0d05cb0b78608edd18"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
